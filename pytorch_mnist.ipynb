{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return  F.log_softmax(x, dim=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,optimizer,train_loader,epoch):\n",
    "    model.train()\n",
    "    for batch_idx,(target,data) in enumerate(train_loader):\n",
    "        data,target=data.to(device,dtype=torch.float),target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=F.nll_loss(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,device,optimizer,test_loader,epoch):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for target, data in test_loader:\n",
    "            \n",
    "            data,target=data.to(device,dtype=torch.float),target.to(device)\n",
    "            output = model(data)\n",
    "            output.shape\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataSet(Dataset):\n",
    "    def __init__(self,csv_file,train=True,transform=None):\n",
    "        self.lastindx=33600\n",
    "        self.fstindx=1\n",
    "        if not train:\n",
    "            self.lastindx=41999\n",
    "            self.fstindx=33601\n",
    "        self.images=pd.read_csv(csv_file)\n",
    "        self.data=self.images.iloc[self.fstindx:self.lastindx,1:]\n",
    "        self.labels=self.images.iloc[self.fstindx:self.lastindx,0].values\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        imgs=self.data.iloc[idx,:].values/255\n",
    "        \n",
    "        return self.labels[idx],imgs.reshape(1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=MnistDataSet('train.csv')\n",
    "testdata=MnistDataSet('train.csv',train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(traindata,batch_size=64, shuffle=True,**kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(testdata,batch_size=64, shuffle=True,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net().to(device)\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(model.parameters(),lr=0.005,momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/33599 (0%)]\tLoss: 0.110704\n",
      "Train Epoch: 1 [640/33599 (2%)]\tLoss: 0.142092\n",
      "Train Epoch: 1 [1280/33599 (4%)]\tLoss: 0.325005\n",
      "Train Epoch: 1 [1920/33599 (6%)]\tLoss: 0.059389\n",
      "Train Epoch: 1 [2560/33599 (8%)]\tLoss: 0.052715\n",
      "Train Epoch: 1 [3200/33599 (10%)]\tLoss: 0.024800\n",
      "Train Epoch: 1 [3840/33599 (11%)]\tLoss: 0.049865\n",
      "Train Epoch: 1 [4480/33599 (13%)]\tLoss: 0.112536\n",
      "Train Epoch: 1 [5120/33599 (15%)]\tLoss: 0.010418\n",
      "Train Epoch: 1 [5760/33599 (17%)]\tLoss: 0.069467\n",
      "Train Epoch: 1 [6400/33599 (19%)]\tLoss: 0.034917\n",
      "Train Epoch: 1 [7040/33599 (21%)]\tLoss: 0.038100\n",
      "Train Epoch: 1 [7680/33599 (23%)]\tLoss: 0.302214\n",
      "Train Epoch: 1 [8320/33599 (25%)]\tLoss: 0.084725\n",
      "Train Epoch: 1 [8960/33599 (27%)]\tLoss: 0.038467\n",
      "Train Epoch: 1 [9600/33599 (29%)]\tLoss: 0.131919\n",
      "Train Epoch: 1 [10240/33599 (30%)]\tLoss: 0.023991\n",
      "Train Epoch: 1 [10880/33599 (32%)]\tLoss: 0.077730\n",
      "Train Epoch: 1 [11520/33599 (34%)]\tLoss: 0.066892\n",
      "Train Epoch: 1 [12160/33599 (36%)]\tLoss: 0.036830\n",
      "Train Epoch: 1 [12800/33599 (38%)]\tLoss: 0.015655\n",
      "Train Epoch: 1 [13440/33599 (40%)]\tLoss: 0.080117\n",
      "Train Epoch: 1 [14080/33599 (42%)]\tLoss: 0.026345\n",
      "Train Epoch: 1 [14720/33599 (44%)]\tLoss: 0.052374\n",
      "Train Epoch: 1 [15360/33599 (46%)]\tLoss: 0.024045\n",
      "Train Epoch: 1 [16000/33599 (48%)]\tLoss: 0.067572\n",
      "Train Epoch: 1 [16640/33599 (50%)]\tLoss: 0.027838\n",
      "Train Epoch: 1 [17280/33599 (51%)]\tLoss: 0.015701\n",
      "Train Epoch: 1 [17920/33599 (53%)]\tLoss: 0.107224\n",
      "Train Epoch: 1 [18560/33599 (55%)]\tLoss: 0.127859\n",
      "Train Epoch: 1 [19200/33599 (57%)]\tLoss: 0.127580\n",
      "Train Epoch: 1 [19840/33599 (59%)]\tLoss: 0.060979\n",
      "Train Epoch: 1 [20480/33599 (61%)]\tLoss: 0.051638\n",
      "Train Epoch: 1 [21120/33599 (63%)]\tLoss: 0.073792\n",
      "Train Epoch: 1 [21760/33599 (65%)]\tLoss: 0.018154\n",
      "Train Epoch: 1 [22400/33599 (67%)]\tLoss: 0.155118\n",
      "Train Epoch: 1 [23040/33599 (69%)]\tLoss: 0.012069\n",
      "Train Epoch: 1 [23680/33599 (70%)]\tLoss: 0.177783\n",
      "Train Epoch: 1 [24320/33599 (72%)]\tLoss: 0.058705\n",
      "Train Epoch: 1 [24960/33599 (74%)]\tLoss: 0.016688\n",
      "Train Epoch: 1 [25600/33599 (76%)]\tLoss: 0.045713\n",
      "Train Epoch: 1 [26240/33599 (78%)]\tLoss: 0.018538\n",
      "Train Epoch: 1 [26880/33599 (80%)]\tLoss: 0.028324\n",
      "Train Epoch: 1 [27520/33599 (82%)]\tLoss: 0.069338\n",
      "Train Epoch: 1 [28160/33599 (84%)]\tLoss: 0.062266\n",
      "Train Epoch: 1 [28800/33599 (86%)]\tLoss: 0.017983\n",
      "Train Epoch: 1 [29440/33599 (88%)]\tLoss: 0.009135\n",
      "Train Epoch: 1 [30080/33599 (90%)]\tLoss: 0.012751\n",
      "Train Epoch: 1 [30720/33599 (91%)]\tLoss: 0.027071\n",
      "Train Epoch: 1 [31360/33599 (93%)]\tLoss: 0.131403\n",
      "Train Epoch: 1 [32000/33599 (95%)]\tLoss: 0.028834\n",
      "Train Epoch: 1 [32640/33599 (97%)]\tLoss: 0.051392\n",
      "Train Epoch: 1 [33280/33599 (99%)]\tLoss: 0.061909\n",
      "\n",
      "Test set: Average loss: 0.0713, Accuracy: 8192/8398 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/33599 (0%)]\tLoss: 0.008601\n",
      "Train Epoch: 2 [640/33599 (2%)]\tLoss: 0.031548\n",
      "Train Epoch: 2 [1280/33599 (4%)]\tLoss: 0.133119\n",
      "Train Epoch: 2 [1920/33599 (6%)]\tLoss: 0.013482\n",
      "Train Epoch: 2 [2560/33599 (8%)]\tLoss: 0.018329\n",
      "Train Epoch: 2 [3200/33599 (10%)]\tLoss: 0.009875\n",
      "Train Epoch: 2 [3840/33599 (11%)]\tLoss: 0.044531\n",
      "Train Epoch: 2 [4480/33599 (13%)]\tLoss: 0.100820\n",
      "Train Epoch: 2 [5120/33599 (15%)]\tLoss: 0.078248\n",
      "Train Epoch: 2 [5760/33599 (17%)]\tLoss: 0.114195\n",
      "Train Epoch: 2 [6400/33599 (19%)]\tLoss: 0.025274\n",
      "Train Epoch: 2 [7040/33599 (21%)]\tLoss: 0.045087\n",
      "Train Epoch: 2 [7680/33599 (23%)]\tLoss: 0.108974\n",
      "Train Epoch: 2 [8320/33599 (25%)]\tLoss: 0.018507\n",
      "Train Epoch: 2 [8960/33599 (27%)]\tLoss: 0.021925\n",
      "Train Epoch: 2 [9600/33599 (29%)]\tLoss: 0.059361\n",
      "Train Epoch: 2 [10240/33599 (30%)]\tLoss: 0.034280\n",
      "Train Epoch: 2 [10880/33599 (32%)]\tLoss: 0.151258\n",
      "Train Epoch: 2 [11520/33599 (34%)]\tLoss: 0.109420\n",
      "Train Epoch: 2 [12160/33599 (36%)]\tLoss: 0.031772\n",
      "Train Epoch: 2 [12800/33599 (38%)]\tLoss: 0.087114\n",
      "Train Epoch: 2 [13440/33599 (40%)]\tLoss: 0.039390\n",
      "Train Epoch: 2 [14080/33599 (42%)]\tLoss: 0.092264\n",
      "Train Epoch: 2 [14720/33599 (44%)]\tLoss: 0.027375\n",
      "Train Epoch: 2 [15360/33599 (46%)]\tLoss: 0.084513\n",
      "Train Epoch: 2 [16000/33599 (48%)]\tLoss: 0.076162\n",
      "Train Epoch: 2 [16640/33599 (50%)]\tLoss: 0.041794\n",
      "Train Epoch: 2 [17280/33599 (51%)]\tLoss: 0.099776\n",
      "Train Epoch: 2 [17920/33599 (53%)]\tLoss: 0.051769\n",
      "Train Epoch: 2 [18560/33599 (55%)]\tLoss: 0.054970\n",
      "Train Epoch: 2 [19200/33599 (57%)]\tLoss: 0.028718\n",
      "Train Epoch: 2 [19840/33599 (59%)]\tLoss: 0.065293\n",
      "Train Epoch: 2 [20480/33599 (61%)]\tLoss: 0.135448\n",
      "Train Epoch: 2 [21120/33599 (63%)]\tLoss: 0.080707\n",
      "Train Epoch: 2 [21760/33599 (65%)]\tLoss: 0.016493\n",
      "Train Epoch: 2 [22400/33599 (67%)]\tLoss: 0.113407\n",
      "Train Epoch: 2 [23040/33599 (69%)]\tLoss: 0.106947\n",
      "Train Epoch: 2 [23680/33599 (70%)]\tLoss: 0.064371\n",
      "Train Epoch: 2 [24320/33599 (72%)]\tLoss: 0.024922\n",
      "Train Epoch: 2 [24960/33599 (74%)]\tLoss: 0.143492\n",
      "Train Epoch: 2 [25600/33599 (76%)]\tLoss: 0.084452\n",
      "Train Epoch: 2 [26240/33599 (78%)]\tLoss: 0.040869\n",
      "Train Epoch: 2 [26880/33599 (80%)]\tLoss: 0.021908\n",
      "Train Epoch: 2 [27520/33599 (82%)]\tLoss: 0.066269\n",
      "Train Epoch: 2 [28160/33599 (84%)]\tLoss: 0.043249\n",
      "Train Epoch: 2 [28800/33599 (86%)]\tLoss: 0.159104\n",
      "Train Epoch: 2 [29440/33599 (88%)]\tLoss: 0.110593\n",
      "Train Epoch: 2 [30080/33599 (90%)]\tLoss: 0.013500\n",
      "Train Epoch: 2 [30720/33599 (91%)]\tLoss: 0.023898\n",
      "Train Epoch: 2 [31360/33599 (93%)]\tLoss: 0.119222\n",
      "Train Epoch: 2 [32000/33599 (95%)]\tLoss: 0.050475\n",
      "Train Epoch: 2 [32640/33599 (97%)]\tLoss: 0.205620\n",
      "Train Epoch: 2 [33280/33599 (99%)]\tLoss: 0.107456\n",
      "\n",
      "Test set: Average loss: 0.0756, Accuracy: 8207/8398 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/33599 (0%)]\tLoss: 0.014648\n",
      "Train Epoch: 3 [640/33599 (2%)]\tLoss: 0.067904\n",
      "Train Epoch: 3 [1280/33599 (4%)]\tLoss: 0.043472\n",
      "Train Epoch: 3 [1920/33599 (6%)]\tLoss: 0.015384\n",
      "Train Epoch: 3 [2560/33599 (8%)]\tLoss: 0.129400\n",
      "Train Epoch: 3 [3200/33599 (10%)]\tLoss: 0.078662\n",
      "Train Epoch: 3 [3840/33599 (11%)]\tLoss: 0.073913\n",
      "Train Epoch: 3 [4480/33599 (13%)]\tLoss: 0.089897\n",
      "Train Epoch: 3 [5120/33599 (15%)]\tLoss: 0.094625\n",
      "Train Epoch: 3 [5760/33599 (17%)]\tLoss: 0.103844\n",
      "Train Epoch: 3 [6400/33599 (19%)]\tLoss: 0.059728\n",
      "Train Epoch: 3 [7040/33599 (21%)]\tLoss: 0.065479\n",
      "Train Epoch: 3 [7680/33599 (23%)]\tLoss: 0.014762\n",
      "Train Epoch: 3 [8320/33599 (25%)]\tLoss: 0.066316\n",
      "Train Epoch: 3 [8960/33599 (27%)]\tLoss: 0.033805\n",
      "Train Epoch: 3 [9600/33599 (29%)]\tLoss: 0.106481\n",
      "Train Epoch: 3 [10240/33599 (30%)]\tLoss: 0.112376\n",
      "Train Epoch: 3 [10880/33599 (32%)]\tLoss: 0.108817\n",
      "Train Epoch: 3 [11520/33599 (34%)]\tLoss: 0.004817\n",
      "Train Epoch: 3 [12160/33599 (36%)]\tLoss: 0.031785\n",
      "Train Epoch: 3 [12800/33599 (38%)]\tLoss: 0.040745\n",
      "Train Epoch: 3 [13440/33599 (40%)]\tLoss: 0.060979\n",
      "Train Epoch: 3 [14080/33599 (42%)]\tLoss: 0.116282\n",
      "Train Epoch: 3 [14720/33599 (44%)]\tLoss: 0.130439\n",
      "Train Epoch: 3 [15360/33599 (46%)]\tLoss: 0.040754\n",
      "Train Epoch: 3 [16000/33599 (48%)]\tLoss: 0.018366\n",
      "Train Epoch: 3 [16640/33599 (50%)]\tLoss: 0.064015\n",
      "Train Epoch: 3 [17280/33599 (51%)]\tLoss: 0.033384\n",
      "Train Epoch: 3 [17920/33599 (53%)]\tLoss: 0.095370\n",
      "Train Epoch: 3 [18560/33599 (55%)]\tLoss: 0.053717\n",
      "Train Epoch: 3 [19200/33599 (57%)]\tLoss: 0.026170\n",
      "Train Epoch: 3 [19840/33599 (59%)]\tLoss: 0.053302\n",
      "Train Epoch: 3 [20480/33599 (61%)]\tLoss: 0.015849\n",
      "Train Epoch: 3 [21120/33599 (63%)]\tLoss: 0.063823\n",
      "Train Epoch: 3 [21760/33599 (65%)]\tLoss: 0.035124\n",
      "Train Epoch: 3 [22400/33599 (67%)]\tLoss: 0.108782\n",
      "Train Epoch: 3 [23040/33599 (69%)]\tLoss: 0.074063\n",
      "Train Epoch: 3 [23680/33599 (70%)]\tLoss: 0.017268\n",
      "Train Epoch: 3 [24320/33599 (72%)]\tLoss: 0.108021\n",
      "Train Epoch: 3 [24960/33599 (74%)]\tLoss: 0.032059\n",
      "Train Epoch: 3 [25600/33599 (76%)]\tLoss: 0.106977\n",
      "Train Epoch: 3 [26240/33599 (78%)]\tLoss: 0.045395\n",
      "Train Epoch: 3 [26880/33599 (80%)]\tLoss: 0.099734\n",
      "Train Epoch: 3 [27520/33599 (82%)]\tLoss: 0.059807\n",
      "Train Epoch: 3 [28160/33599 (84%)]\tLoss: 0.103315\n",
      "Train Epoch: 3 [28800/33599 (86%)]\tLoss: 0.034490\n",
      "Train Epoch: 3 [29440/33599 (88%)]\tLoss: 0.036269\n",
      "Train Epoch: 3 [30080/33599 (90%)]\tLoss: 0.023045\n",
      "Train Epoch: 3 [30720/33599 (91%)]\tLoss: 0.108441\n",
      "Train Epoch: 3 [31360/33599 (93%)]\tLoss: 0.102798\n",
      "Train Epoch: 3 [32000/33599 (95%)]\tLoss: 0.120541\n",
      "Train Epoch: 3 [32640/33599 (97%)]\tLoss: 0.023505\n",
      "Train Epoch: 3 [33280/33599 (99%)]\tLoss: 0.069369\n",
      "\n",
      "Test set: Average loss: 0.0649, Accuracy: 8225/8398 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/33599 (0%)]\tLoss: 0.006039\n",
      "Train Epoch: 4 [640/33599 (2%)]\tLoss: 0.082543\n",
      "Train Epoch: 4 [1280/33599 (4%)]\tLoss: 0.028959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [1920/33599 (6%)]\tLoss: 0.094882\n",
      "Train Epoch: 4 [2560/33599 (8%)]\tLoss: 0.244039\n",
      "Train Epoch: 4 [3200/33599 (10%)]\tLoss: 0.044469\n",
      "Train Epoch: 4 [3840/33599 (11%)]\tLoss: 0.036531\n",
      "Train Epoch: 4 [4480/33599 (13%)]\tLoss: 0.141158\n",
      "Train Epoch: 4 [5120/33599 (15%)]\tLoss: 0.010452\n",
      "Train Epoch: 4 [5760/33599 (17%)]\tLoss: 0.064941\n",
      "Train Epoch: 4 [6400/33599 (19%)]\tLoss: 0.087034\n",
      "Train Epoch: 4 [7040/33599 (21%)]\tLoss: 0.056386\n",
      "Train Epoch: 4 [7680/33599 (23%)]\tLoss: 0.028495\n",
      "Train Epoch: 4 [8320/33599 (25%)]\tLoss: 0.014505\n",
      "Train Epoch: 4 [8960/33599 (27%)]\tLoss: 0.111900\n",
      "Train Epoch: 4 [9600/33599 (29%)]\tLoss: 0.038549\n",
      "Train Epoch: 4 [10240/33599 (30%)]\tLoss: 0.086355\n",
      "Train Epoch: 4 [10880/33599 (32%)]\tLoss: 0.008182\n",
      "Train Epoch: 4 [11520/33599 (34%)]\tLoss: 0.054240\n",
      "Train Epoch: 4 [12160/33599 (36%)]\tLoss: 0.020069\n",
      "Train Epoch: 4 [12800/33599 (38%)]\tLoss: 0.032888\n",
      "Train Epoch: 4 [13440/33599 (40%)]\tLoss: 0.065357\n",
      "Train Epoch: 4 [14080/33599 (42%)]\tLoss: 0.040872\n",
      "Train Epoch: 4 [14720/33599 (44%)]\tLoss: 0.009520\n",
      "Train Epoch: 4 [15360/33599 (46%)]\tLoss: 0.009544\n",
      "Train Epoch: 4 [16000/33599 (48%)]\tLoss: 0.047868\n",
      "Train Epoch: 4 [16640/33599 (50%)]\tLoss: 0.095998\n",
      "Train Epoch: 4 [17280/33599 (51%)]\tLoss: 0.062831\n",
      "Train Epoch: 4 [17920/33599 (53%)]\tLoss: 0.112917\n",
      "Train Epoch: 4 [18560/33599 (55%)]\tLoss: 0.045540\n",
      "Train Epoch: 4 [19200/33599 (57%)]\tLoss: 0.126826\n",
      "Train Epoch: 4 [19840/33599 (59%)]\tLoss: 0.026776\n",
      "Train Epoch: 4 [20480/33599 (61%)]\tLoss: 0.014054\n",
      "Train Epoch: 4 [21120/33599 (63%)]\tLoss: 0.045050\n",
      "Train Epoch: 4 [21760/33599 (65%)]\tLoss: 0.042379\n",
      "Train Epoch: 4 [22400/33599 (67%)]\tLoss: 0.028420\n",
      "Train Epoch: 4 [23040/33599 (69%)]\tLoss: 0.053147\n",
      "Train Epoch: 4 [23680/33599 (70%)]\tLoss: 0.135248\n",
      "Train Epoch: 4 [24320/33599 (72%)]\tLoss: 0.139780\n",
      "Train Epoch: 4 [24960/33599 (74%)]\tLoss: 0.085349\n",
      "Train Epoch: 4 [25600/33599 (76%)]\tLoss: 0.007910\n",
      "Train Epoch: 4 [26240/33599 (78%)]\tLoss: 0.017947\n",
      "Train Epoch: 4 [26880/33599 (80%)]\tLoss: 0.051993\n",
      "Train Epoch: 4 [27520/33599 (82%)]\tLoss: 0.111194\n",
      "Train Epoch: 4 [28160/33599 (84%)]\tLoss: 0.015773\n",
      "Train Epoch: 4 [28800/33599 (86%)]\tLoss: 0.033785\n",
      "Train Epoch: 4 [29440/33599 (88%)]\tLoss: 0.027061\n",
      "Train Epoch: 4 [30080/33599 (90%)]\tLoss: 0.100420\n",
      "Train Epoch: 4 [30720/33599 (91%)]\tLoss: 0.072198\n",
      "Train Epoch: 4 [31360/33599 (93%)]\tLoss: 0.058402\n",
      "Train Epoch: 4 [32000/33599 (95%)]\tLoss: 0.057196\n",
      "Train Epoch: 4 [32640/33599 (97%)]\tLoss: 0.093020\n",
      "Train Epoch: 4 [33280/33599 (99%)]\tLoss: 0.088428\n",
      "\n",
      "Test set: Average loss: 0.0690, Accuracy: 8209/8398 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/33599 (0%)]\tLoss: 0.100705\n",
      "Train Epoch: 5 [640/33599 (2%)]\tLoss: 0.026615\n",
      "Train Epoch: 5 [1280/33599 (4%)]\tLoss: 0.079199\n",
      "Train Epoch: 5 [1920/33599 (6%)]\tLoss: 0.102222\n",
      "Train Epoch: 5 [2560/33599 (8%)]\tLoss: 0.038671\n",
      "Train Epoch: 5 [3200/33599 (10%)]\tLoss: 0.045237\n",
      "Train Epoch: 5 [3840/33599 (11%)]\tLoss: 0.027709\n",
      "Train Epoch: 5 [4480/33599 (13%)]\tLoss: 0.029304\n",
      "Train Epoch: 5 [5120/33599 (15%)]\tLoss: 0.097607\n",
      "Train Epoch: 5 [5760/33599 (17%)]\tLoss: 0.126079\n",
      "Train Epoch: 5 [6400/33599 (19%)]\tLoss: 0.326872\n",
      "Train Epoch: 5 [7040/33599 (21%)]\tLoss: 0.121043\n",
      "Train Epoch: 5 [7680/33599 (23%)]\tLoss: 0.093596\n",
      "Train Epoch: 5 [8320/33599 (25%)]\tLoss: 0.025826\n",
      "Train Epoch: 5 [8960/33599 (27%)]\tLoss: 0.029264\n",
      "Train Epoch: 5 [9600/33599 (29%)]\tLoss: 0.040540\n",
      "Train Epoch: 5 [10240/33599 (30%)]\tLoss: 0.047541\n",
      "Train Epoch: 5 [10880/33599 (32%)]\tLoss: 0.016163\n",
      "Train Epoch: 5 [11520/33599 (34%)]\tLoss: 0.036811\n",
      "Train Epoch: 5 [12160/33599 (36%)]\tLoss: 0.032227\n",
      "Train Epoch: 5 [12800/33599 (38%)]\tLoss: 0.048266\n",
      "Train Epoch: 5 [13440/33599 (40%)]\tLoss: 0.090891\n",
      "Train Epoch: 5 [14080/33599 (42%)]\tLoss: 0.009256\n",
      "Train Epoch: 5 [14720/33599 (44%)]\tLoss: 0.078125\n",
      "Train Epoch: 5 [15360/33599 (46%)]\tLoss: 0.032868\n",
      "Train Epoch: 5 [16000/33599 (48%)]\tLoss: 0.042386\n",
      "Train Epoch: 5 [16640/33599 (50%)]\tLoss: 0.051972\n",
      "Train Epoch: 5 [17280/33599 (51%)]\tLoss: 0.076781\n",
      "Train Epoch: 5 [17920/33599 (53%)]\tLoss: 0.048609\n",
      "Train Epoch: 5 [18560/33599 (55%)]\tLoss: 0.067197\n",
      "Train Epoch: 5 [19200/33599 (57%)]\tLoss: 0.025097\n",
      "Train Epoch: 5 [19840/33599 (59%)]\tLoss: 0.031054\n",
      "Train Epoch: 5 [20480/33599 (61%)]\tLoss: 0.013786\n",
      "Train Epoch: 5 [21120/33599 (63%)]\tLoss: 0.115344\n",
      "Train Epoch: 5 [21760/33599 (65%)]\tLoss: 0.046674\n",
      "Train Epoch: 5 [22400/33599 (67%)]\tLoss: 0.072804\n",
      "Train Epoch: 5 [23040/33599 (69%)]\tLoss: 0.037551\n",
      "Train Epoch: 5 [23680/33599 (70%)]\tLoss: 0.086764\n",
      "Train Epoch: 5 [24320/33599 (72%)]\tLoss: 0.135076\n",
      "Train Epoch: 5 [24960/33599 (74%)]\tLoss: 0.070913\n",
      "Train Epoch: 5 [25600/33599 (76%)]\tLoss: 0.076047\n",
      "Train Epoch: 5 [26240/33599 (78%)]\tLoss: 0.045485\n",
      "Train Epoch: 5 [26880/33599 (80%)]\tLoss: 0.023948\n",
      "Train Epoch: 5 [27520/33599 (82%)]\tLoss: 0.051315\n",
      "Train Epoch: 5 [28160/33599 (84%)]\tLoss: 0.036964\n",
      "Train Epoch: 5 [28800/33599 (86%)]\tLoss: 0.093797\n",
      "Train Epoch: 5 [29440/33599 (88%)]\tLoss: 0.155377\n",
      "Train Epoch: 5 [30080/33599 (90%)]\tLoss: 0.035440\n",
      "Train Epoch: 5 [30720/33599 (91%)]\tLoss: 0.036642\n",
      "Train Epoch: 5 [31360/33599 (93%)]\tLoss: 0.100791\n",
      "Train Epoch: 5 [32000/33599 (95%)]\tLoss: 0.119771\n",
      "Train Epoch: 5 [32640/33599 (97%)]\tLoss: 0.079787\n",
      "Train Epoch: 5 [33280/33599 (99%)]\tLoss: 0.029451\n",
      "\n",
      "Test set: Average loss: 0.0650, Accuracy: 8229/8398 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/33599 (0%)]\tLoss: 0.007603\n",
      "Train Epoch: 6 [640/33599 (2%)]\tLoss: 0.035325\n",
      "Train Epoch: 6 [1280/33599 (4%)]\tLoss: 0.055262\n",
      "Train Epoch: 6 [1920/33599 (6%)]\tLoss: 0.065843\n",
      "Train Epoch: 6 [2560/33599 (8%)]\tLoss: 0.047997\n",
      "Train Epoch: 6 [3200/33599 (10%)]\tLoss: 0.017759\n",
      "Train Epoch: 6 [3840/33599 (11%)]\tLoss: 0.040557\n",
      "Train Epoch: 6 [4480/33599 (13%)]\tLoss: 0.012628\n",
      "Train Epoch: 6 [5120/33599 (15%)]\tLoss: 0.040580\n",
      "Train Epoch: 6 [5760/33599 (17%)]\tLoss: 0.009521\n",
      "Train Epoch: 6 [6400/33599 (19%)]\tLoss: 0.022039\n",
      "Train Epoch: 6 [7040/33599 (21%)]\tLoss: 0.014244\n",
      "Train Epoch: 6 [7680/33599 (23%)]\tLoss: 0.062269\n",
      "Train Epoch: 6 [8320/33599 (25%)]\tLoss: 0.039221\n",
      "Train Epoch: 6 [8960/33599 (27%)]\tLoss: 0.005867\n",
      "Train Epoch: 6 [9600/33599 (29%)]\tLoss: 0.027753\n",
      "Train Epoch: 6 [10240/33599 (30%)]\tLoss: 0.065402\n",
      "Train Epoch: 6 [10880/33599 (32%)]\tLoss: 0.031703\n",
      "Train Epoch: 6 [11520/33599 (34%)]\tLoss: 0.050630\n",
      "Train Epoch: 6 [12160/33599 (36%)]\tLoss: 0.121842\n",
      "Train Epoch: 6 [12800/33599 (38%)]\tLoss: 0.028955\n",
      "Train Epoch: 6 [13440/33599 (40%)]\tLoss: 0.053461\n",
      "Train Epoch: 6 [14080/33599 (42%)]\tLoss: 0.081229\n",
      "Train Epoch: 6 [14720/33599 (44%)]\tLoss: 0.045361\n",
      "Train Epoch: 6 [15360/33599 (46%)]\tLoss: 0.093502\n",
      "Train Epoch: 6 [16000/33599 (48%)]\tLoss: 0.094063\n",
      "Train Epoch: 6 [16640/33599 (50%)]\tLoss: 0.051774\n",
      "Train Epoch: 6 [17280/33599 (51%)]\tLoss: 0.031405\n",
      "Train Epoch: 6 [17920/33599 (53%)]\tLoss: 0.100848\n",
      "Train Epoch: 6 [18560/33599 (55%)]\tLoss: 0.048119\n",
      "Train Epoch: 6 [19200/33599 (57%)]\tLoss: 0.075344\n",
      "Train Epoch: 6 [19840/33599 (59%)]\tLoss: 0.034286\n",
      "Train Epoch: 6 [20480/33599 (61%)]\tLoss: 0.097240\n",
      "Train Epoch: 6 [21120/33599 (63%)]\tLoss: 0.032200\n",
      "Train Epoch: 6 [21760/33599 (65%)]\tLoss: 0.009340\n",
      "Train Epoch: 6 [22400/33599 (67%)]\tLoss: 0.009496\n",
      "Train Epoch: 6 [23040/33599 (69%)]\tLoss: 0.027281\n",
      "Train Epoch: 6 [23680/33599 (70%)]\tLoss: 0.008787\n",
      "Train Epoch: 6 [24320/33599 (72%)]\tLoss: 0.014752\n",
      "Train Epoch: 6 [24960/33599 (74%)]\tLoss: 0.065978\n",
      "Train Epoch: 6 [25600/33599 (76%)]\tLoss: 0.036965\n",
      "Train Epoch: 6 [26240/33599 (78%)]\tLoss: 0.067013\n",
      "Train Epoch: 6 [26880/33599 (80%)]\tLoss: 0.023311\n",
      "Train Epoch: 6 [27520/33599 (82%)]\tLoss: 0.011379\n",
      "Train Epoch: 6 [28160/33599 (84%)]\tLoss: 0.216620\n",
      "Train Epoch: 6 [28800/33599 (86%)]\tLoss: 0.077987\n",
      "Train Epoch: 6 [29440/33599 (88%)]\tLoss: 0.015549\n",
      "Train Epoch: 6 [30080/33599 (90%)]\tLoss: 0.018625\n",
      "Train Epoch: 6 [30720/33599 (91%)]\tLoss: 0.075878\n",
      "Train Epoch: 6 [31360/33599 (93%)]\tLoss: 0.023804\n",
      "Train Epoch: 6 [32000/33599 (95%)]\tLoss: 0.088129\n",
      "Train Epoch: 6 [32640/33599 (97%)]\tLoss: 0.119575\n",
      "Train Epoch: 6 [33280/33599 (99%)]\tLoss: 0.074699\n",
      "\n",
      "Test set: Average loss: 0.0640, Accuracy: 8216/8398 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/33599 (0%)]\tLoss: 0.011182\n",
      "Train Epoch: 7 [640/33599 (2%)]\tLoss: 0.024482\n",
      "Train Epoch: 7 [1280/33599 (4%)]\tLoss: 0.024810\n",
      "Train Epoch: 7 [1920/33599 (6%)]\tLoss: 0.010324\n",
      "Train Epoch: 7 [2560/33599 (8%)]\tLoss: 0.059236\n",
      "Train Epoch: 7 [3200/33599 (10%)]\tLoss: 0.010487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [3840/33599 (11%)]\tLoss: 0.147505\n",
      "Train Epoch: 7 [4480/33599 (13%)]\tLoss: 0.026494\n",
      "Train Epoch: 7 [5120/33599 (15%)]\tLoss: 0.006327\n",
      "Train Epoch: 7 [5760/33599 (17%)]\tLoss: 0.039848\n",
      "Train Epoch: 7 [6400/33599 (19%)]\tLoss: 0.010156\n",
      "Train Epoch: 7 [7040/33599 (21%)]\tLoss: 0.021598\n",
      "Train Epoch: 7 [7680/33599 (23%)]\tLoss: 0.026269\n",
      "Train Epoch: 7 [8320/33599 (25%)]\tLoss: 0.045109\n",
      "Train Epoch: 7 [8960/33599 (27%)]\tLoss: 0.013266\n",
      "Train Epoch: 7 [9600/33599 (29%)]\tLoss: 0.024349\n",
      "Train Epoch: 7 [10240/33599 (30%)]\tLoss: 0.016220\n",
      "Train Epoch: 7 [10880/33599 (32%)]\tLoss: 0.010144\n",
      "Train Epoch: 7 [11520/33599 (34%)]\tLoss: 0.074547\n",
      "Train Epoch: 7 [12160/33599 (36%)]\tLoss: 0.018968\n",
      "Train Epoch: 7 [12800/33599 (38%)]\tLoss: 0.031676\n",
      "Train Epoch: 7 [13440/33599 (40%)]\tLoss: 0.056578\n",
      "Train Epoch: 7 [14080/33599 (42%)]\tLoss: 0.026375\n",
      "Train Epoch: 7 [14720/33599 (44%)]\tLoss: 0.046841\n",
      "Train Epoch: 7 [15360/33599 (46%)]\tLoss: 0.033798\n",
      "Train Epoch: 7 [16000/33599 (48%)]\tLoss: 0.031335\n",
      "Train Epoch: 7 [16640/33599 (50%)]\tLoss: 0.045403\n",
      "Train Epoch: 7 [17280/33599 (51%)]\tLoss: 0.021555\n",
      "Train Epoch: 7 [17920/33599 (53%)]\tLoss: 0.009204\n",
      "Train Epoch: 7 [18560/33599 (55%)]\tLoss: 0.147360\n",
      "Train Epoch: 7 [19200/33599 (57%)]\tLoss: 0.035198\n",
      "Train Epoch: 7 [19840/33599 (59%)]\tLoss: 0.022298\n",
      "Train Epoch: 7 [20480/33599 (61%)]\tLoss: 0.052483\n",
      "Train Epoch: 7 [21120/33599 (63%)]\tLoss: 0.007618\n",
      "Train Epoch: 7 [21760/33599 (65%)]\tLoss: 0.054231\n",
      "Train Epoch: 7 [22400/33599 (67%)]\tLoss: 0.013966\n",
      "Train Epoch: 7 [23040/33599 (69%)]\tLoss: 0.080353\n",
      "Train Epoch: 7 [23680/33599 (70%)]\tLoss: 0.005727\n",
      "Train Epoch: 7 [24320/33599 (72%)]\tLoss: 0.068365\n",
      "Train Epoch: 7 [24960/33599 (74%)]\tLoss: 0.013545\n",
      "Train Epoch: 7 [25600/33599 (76%)]\tLoss: 0.211537\n",
      "Train Epoch: 7 [26240/33599 (78%)]\tLoss: 0.033079\n",
      "Train Epoch: 7 [26880/33599 (80%)]\tLoss: 0.015823\n",
      "Train Epoch: 7 [27520/33599 (82%)]\tLoss: 0.119739\n",
      "Train Epoch: 7 [28160/33599 (84%)]\tLoss: 0.050686\n",
      "Train Epoch: 7 [28800/33599 (86%)]\tLoss: 0.008613\n",
      "Train Epoch: 7 [29440/33599 (88%)]\tLoss: 0.063069\n",
      "Train Epoch: 7 [30080/33599 (90%)]\tLoss: 0.090318\n",
      "Train Epoch: 7 [30720/33599 (91%)]\tLoss: 0.012814\n",
      "Train Epoch: 7 [31360/33599 (93%)]\tLoss: 0.047521\n",
      "Train Epoch: 7 [32000/33599 (95%)]\tLoss: 0.042847\n",
      "Train Epoch: 7 [32640/33599 (97%)]\tLoss: 0.026888\n",
      "Train Epoch: 7 [33280/33599 (99%)]\tLoss: 0.064429\n",
      "\n",
      "Test set: Average loss: 0.0664, Accuracy: 8217/8398 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/33599 (0%)]\tLoss: 0.026883\n",
      "Train Epoch: 8 [640/33599 (2%)]\tLoss: 0.075422\n",
      "Train Epoch: 8 [1280/33599 (4%)]\tLoss: 0.054445\n",
      "Train Epoch: 8 [1920/33599 (6%)]\tLoss: 0.067899\n",
      "Train Epoch: 8 [2560/33599 (8%)]\tLoss: 0.030210\n",
      "Train Epoch: 8 [3200/33599 (10%)]\tLoss: 0.083686\n",
      "Train Epoch: 8 [3840/33599 (11%)]\tLoss: 0.169404\n",
      "Train Epoch: 8 [4480/33599 (13%)]\tLoss: 0.183177\n",
      "Train Epoch: 8 [5120/33599 (15%)]\tLoss: 0.052273\n",
      "Train Epoch: 8 [5760/33599 (17%)]\tLoss: 0.064962\n",
      "Train Epoch: 8 [6400/33599 (19%)]\tLoss: 0.012272\n",
      "Train Epoch: 8 [7040/33599 (21%)]\tLoss: 0.013195\n",
      "Train Epoch: 8 [7680/33599 (23%)]\tLoss: 0.037004\n",
      "Train Epoch: 8 [8320/33599 (25%)]\tLoss: 0.059244\n",
      "Train Epoch: 8 [8960/33599 (27%)]\tLoss: 0.033796\n",
      "Train Epoch: 8 [9600/33599 (29%)]\tLoss: 0.187172\n",
      "Train Epoch: 8 [10240/33599 (30%)]\tLoss: 0.006034\n",
      "Train Epoch: 8 [10880/33599 (32%)]\tLoss: 0.057710\n",
      "Train Epoch: 8 [11520/33599 (34%)]\tLoss: 0.009332\n",
      "Train Epoch: 8 [12160/33599 (36%)]\tLoss: 0.038575\n",
      "Train Epoch: 8 [12800/33599 (38%)]\tLoss: 0.062266\n",
      "Train Epoch: 8 [13440/33599 (40%)]\tLoss: 0.052062\n",
      "Train Epoch: 8 [14080/33599 (42%)]\tLoss: 0.050066\n",
      "Train Epoch: 8 [14720/33599 (44%)]\tLoss: 0.023156\n",
      "Train Epoch: 8 [15360/33599 (46%)]\tLoss: 0.032666\n",
      "Train Epoch: 8 [16000/33599 (48%)]\tLoss: 0.113603\n",
      "Train Epoch: 8 [16640/33599 (50%)]\tLoss: 0.029744\n",
      "Train Epoch: 8 [17280/33599 (51%)]\tLoss: 0.010997\n",
      "Train Epoch: 8 [17920/33599 (53%)]\tLoss: 0.065612\n",
      "Train Epoch: 8 [18560/33599 (55%)]\tLoss: 0.002409\n",
      "Train Epoch: 8 [19200/33599 (57%)]\tLoss: 0.009000\n",
      "Train Epoch: 8 [19840/33599 (59%)]\tLoss: 0.106458\n",
      "Train Epoch: 8 [20480/33599 (61%)]\tLoss: 0.040708\n",
      "Train Epoch: 8 [21120/33599 (63%)]\tLoss: 0.026310\n",
      "Train Epoch: 8 [21760/33599 (65%)]\tLoss: 0.007784\n",
      "Train Epoch: 8 [22400/33599 (67%)]\tLoss: 0.054240\n",
      "Train Epoch: 8 [23040/33599 (69%)]\tLoss: 0.007991\n",
      "Train Epoch: 8 [23680/33599 (70%)]\tLoss: 0.023481\n",
      "Train Epoch: 8 [24320/33599 (72%)]\tLoss: 0.030869\n",
      "Train Epoch: 8 [24960/33599 (74%)]\tLoss: 0.098441\n",
      "Train Epoch: 8 [25600/33599 (76%)]\tLoss: 0.060270\n",
      "Train Epoch: 8 [26240/33599 (78%)]\tLoss: 0.024302\n",
      "Train Epoch: 8 [26880/33599 (80%)]\tLoss: 0.111424\n",
      "Train Epoch: 8 [27520/33599 (82%)]\tLoss: 0.007085\n",
      "Train Epoch: 8 [28160/33599 (84%)]\tLoss: 0.036200\n",
      "Train Epoch: 8 [28800/33599 (86%)]\tLoss: 0.045654\n",
      "Train Epoch: 8 [29440/33599 (88%)]\tLoss: 0.078632\n",
      "Train Epoch: 8 [30080/33599 (90%)]\tLoss: 0.036589\n",
      "Train Epoch: 8 [30720/33599 (91%)]\tLoss: 0.026208\n",
      "Train Epoch: 8 [31360/33599 (93%)]\tLoss: 0.024655\n",
      "Train Epoch: 8 [32000/33599 (95%)]\tLoss: 0.012833\n",
      "Train Epoch: 8 [32640/33599 (97%)]\tLoss: 0.020236\n",
      "Train Epoch: 8 [33280/33599 (99%)]\tLoss: 0.011381\n",
      "\n",
      "Test set: Average loss: 0.0632, Accuracy: 8220/8398 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/33599 (0%)]\tLoss: 0.033793\n",
      "Train Epoch: 9 [640/33599 (2%)]\tLoss: 0.069055\n",
      "Train Epoch: 9 [1280/33599 (4%)]\tLoss: 0.040669\n",
      "Train Epoch: 9 [1920/33599 (6%)]\tLoss: 0.068396\n",
      "Train Epoch: 9 [2560/33599 (8%)]\tLoss: 0.071540\n",
      "Train Epoch: 9 [3200/33599 (10%)]\tLoss: 0.051265\n",
      "Train Epoch: 9 [3840/33599 (11%)]\tLoss: 0.014926\n",
      "Train Epoch: 9 [4480/33599 (13%)]\tLoss: 0.069715\n",
      "Train Epoch: 9 [5120/33599 (15%)]\tLoss: 0.067879\n",
      "Train Epoch: 9 [5760/33599 (17%)]\tLoss: 0.054447\n",
      "Train Epoch: 9 [6400/33599 (19%)]\tLoss: 0.108087\n",
      "Train Epoch: 9 [7040/33599 (21%)]\tLoss: 0.032245\n",
      "Train Epoch: 9 [7680/33599 (23%)]\tLoss: 0.155861\n",
      "Train Epoch: 9 [8320/33599 (25%)]\tLoss: 0.043136\n",
      "Train Epoch: 9 [8960/33599 (27%)]\tLoss: 0.003307\n",
      "Train Epoch: 9 [9600/33599 (29%)]\tLoss: 0.011598\n",
      "Train Epoch: 9 [10240/33599 (30%)]\tLoss: 0.012602\n",
      "Train Epoch: 9 [10880/33599 (32%)]\tLoss: 0.073025\n",
      "Train Epoch: 9 [11520/33599 (34%)]\tLoss: 0.019601\n",
      "Train Epoch: 9 [12160/33599 (36%)]\tLoss: 0.015386\n",
      "Train Epoch: 9 [12800/33599 (38%)]\tLoss: 0.004021\n",
      "Train Epoch: 9 [13440/33599 (40%)]\tLoss: 0.108767\n",
      "Train Epoch: 9 [14080/33599 (42%)]\tLoss: 0.057028\n",
      "Train Epoch: 9 [14720/33599 (44%)]\tLoss: 0.027495\n",
      "Train Epoch: 9 [15360/33599 (46%)]\tLoss: 0.101720\n",
      "Train Epoch: 9 [16000/33599 (48%)]\tLoss: 0.025278\n",
      "Train Epoch: 9 [16640/33599 (50%)]\tLoss: 0.015479\n",
      "Train Epoch: 9 [17280/33599 (51%)]\tLoss: 0.045765\n",
      "Train Epoch: 9 [17920/33599 (53%)]\tLoss: 0.163718\n",
      "Train Epoch: 9 [18560/33599 (55%)]\tLoss: 0.020206\n",
      "Train Epoch: 9 [19200/33599 (57%)]\tLoss: 0.059136\n",
      "Train Epoch: 9 [19840/33599 (59%)]\tLoss: 0.011124\n",
      "Train Epoch: 9 [20480/33599 (61%)]\tLoss: 0.066961\n",
      "Train Epoch: 9 [21120/33599 (63%)]\tLoss: 0.032412\n",
      "Train Epoch: 9 [21760/33599 (65%)]\tLoss: 0.036657\n",
      "Train Epoch: 9 [22400/33599 (67%)]\tLoss: 0.012059\n",
      "Train Epoch: 9 [23040/33599 (69%)]\tLoss: 0.036821\n",
      "Train Epoch: 9 [23680/33599 (70%)]\tLoss: 0.071675\n",
      "Train Epoch: 9 [24320/33599 (72%)]\tLoss: 0.016932\n",
      "Train Epoch: 9 [24960/33599 (74%)]\tLoss: 0.031286\n",
      "Train Epoch: 9 [25600/33599 (76%)]\tLoss: 0.047410\n",
      "Train Epoch: 9 [26240/33599 (78%)]\tLoss: 0.037908\n",
      "Train Epoch: 9 [26880/33599 (80%)]\tLoss: 0.017532\n",
      "Train Epoch: 9 [27520/33599 (82%)]\tLoss: 0.071526\n",
      "Train Epoch: 9 [28160/33599 (84%)]\tLoss: 0.119086\n",
      "Train Epoch: 9 [28800/33599 (86%)]\tLoss: 0.031125\n",
      "Train Epoch: 9 [29440/33599 (88%)]\tLoss: 0.010429\n",
      "Train Epoch: 9 [30080/33599 (90%)]\tLoss: 0.026342\n",
      "Train Epoch: 9 [30720/33599 (91%)]\tLoss: 0.091374\n",
      "Train Epoch: 9 [31360/33599 (93%)]\tLoss: 0.078155\n",
      "Train Epoch: 9 [32000/33599 (95%)]\tLoss: 0.099528\n",
      "Train Epoch: 9 [32640/33599 (97%)]\tLoss: 0.065817\n",
      "Train Epoch: 9 [33280/33599 (99%)]\tLoss: 0.051773\n",
      "\n",
      "Test set: Average loss: 0.0627, Accuracy: 8232/8398 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/33599 (0%)]\tLoss: 0.030976\n",
      "Train Epoch: 10 [640/33599 (2%)]\tLoss: 0.059084\n",
      "Train Epoch: 10 [1280/33599 (4%)]\tLoss: 0.031762\n",
      "Train Epoch: 10 [1920/33599 (6%)]\tLoss: 0.014968\n",
      "Train Epoch: 10 [2560/33599 (8%)]\tLoss: 0.008028\n",
      "Train Epoch: 10 [3200/33599 (10%)]\tLoss: 0.016066\n",
      "Train Epoch: 10 [3840/33599 (11%)]\tLoss: 0.075487\n",
      "Train Epoch: 10 [4480/33599 (13%)]\tLoss: 0.076925\n",
      "Train Epoch: 10 [5120/33599 (15%)]\tLoss: 0.066791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [5760/33599 (17%)]\tLoss: 0.089716\n",
      "Train Epoch: 10 [6400/33599 (19%)]\tLoss: 0.038911\n",
      "Train Epoch: 10 [7040/33599 (21%)]\tLoss: 0.069930\n",
      "Train Epoch: 10 [7680/33599 (23%)]\tLoss: 0.028952\n",
      "Train Epoch: 10 [8320/33599 (25%)]\tLoss: 0.131192\n",
      "Train Epoch: 10 [8960/33599 (27%)]\tLoss: 0.013628\n",
      "Train Epoch: 10 [9600/33599 (29%)]\tLoss: 0.053044\n",
      "Train Epoch: 10 [10240/33599 (30%)]\tLoss: 0.070264\n",
      "Train Epoch: 10 [10880/33599 (32%)]\tLoss: 0.008604\n",
      "Train Epoch: 10 [11520/33599 (34%)]\tLoss: 0.014168\n",
      "Train Epoch: 10 [12160/33599 (36%)]\tLoss: 0.017646\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,20):\n",
    "    train(model,device,optimizer,train_loader,epoch)\n",
    "    test(model,device,optimizer,test_loader,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Visualize some predections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe57f0062b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe57f03b240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label,img=testdata[423]\n",
    "output = model(torch.tensor(img).view(1,1,28,28).to(device,dtype=torch.float))\n",
    "print(torch.argmax(output, dim=1))\n",
    "plt.imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall: 9 Predicted: tensor([6], device='cuda:0')\n",
      "Actuall: 2 Predicted: tensor([2], device='cuda:0')\n",
      "Actuall: 5 Predicted: tensor([6], device='cuda:0')\n",
      "Actuall: 7 Predicted: tensor([2], device='cuda:0')\n",
      "Actuall: 6 Predicted: tensor([8], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "testimgs=['9','2','5','7','6'] ## Manual input \n",
    "for i in testimgs:\n",
    "    xtest=mpimg.imread('testimgs/'+i+'.jpg')\n",
    "    #plt.imshow(xtest/255)\n",
    "    print('Actuall: '+i,end='')\n",
    "    xtest=xtest[:,:,0]\n",
    "    xtest=xtest.reshape(1,1,28,28)\n",
    "    output = model(torch.tensor(xtest).to(device,dtype=torch.float))\n",
    "    \n",
    "    print(' Predicted: ',end='')\n",
    "    print(torch.argmax(output, dim=1))\n",
    "    #|print(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
